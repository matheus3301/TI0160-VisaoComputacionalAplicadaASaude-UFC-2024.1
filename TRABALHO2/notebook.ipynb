{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e Definição de métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vitor\\Desktop\\TI0160-VisaoComputacionalAplicadaASaude-UFC-2024.1\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from segmentation_models_pytorch import Unet\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import torchmetrics\n",
    "from medpy.metric.binary import hd, asd\n",
    "import time\n",
    "\n",
    "\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetBreastCancer(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, image_size=(256, 256)):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # Define transformations for grayscale images and masks\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize(self.image_size),      # Resize image to fixed size\n",
    "            transforms.ToTensor(),                   # Convert image to PyTorch tensor\n",
    "        ])\n",
    "        \n",
    "        self.mask_transform = transforms.Compose([\n",
    "            transforms.Resize(self.image_size, interpolation=Image.NEAREST),  # Resize mask using nearest neighbor\n",
    "            transforms.ToTensor(),                                          # Convert mask to tensor\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Open image and mask in grayscale\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')  # 'L' ensures grayscale (single channel)\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')    # Mask is also in grayscale\n",
    "\n",
    "        # Apply transformations\n",
    "        image = self.image_transform(image)\n",
    "        mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_dir = '../DATA/raw'\n",
    "categories = ['benign', 'malignant', 'normal']\n",
    "\n",
    "train_image_paths = []\n",
    "val_image_paths = []\n",
    "train_mask_paths = []\n",
    "val_mask_paths = []\n",
    "\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(base_dir, category)\n",
    "    category_image_paths = []\n",
    "    category_mask_paths = []\n",
    "    \n",
    "    for fname in os.listdir(category_dir):\n",
    "        if fname.endswith('_mask.png'):\n",
    "            category_mask_paths.append(os.path.join(category_dir, fname))\n",
    "        else:\n",
    "            category_image_paths.append(os.path.join(category_dir, fname))\n",
    "    \n",
    "    # Dividir os caminhos em conjuntos de treino e validação para cada categoria\n",
    "    train_img, val_img, train_mask, val_mask = train_test_split(\n",
    "        category_image_paths, category_mask_paths, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    train_image_paths.extend(train_img)\n",
    "    val_image_paths.extend(val_img)\n",
    "    train_mask_paths.extend(train_mask)\n",
    "    val_mask_paths.extend(val_mask)\n",
    "\n",
    "# Criar instâncias dos datasets de treino e validação\n",
    "train_dataset = DatasetBreastCancer(train_image_paths, train_mask_paths)\n",
    "val_dataset = DatasetBreastCancer(val_image_paths, val_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Definindo o dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, masks in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dice_coefficient(preds, targets, threshold=0.5, epsilon=1e-6):\n",
    "    # Apply threshold to get binary predictions\n",
    "    preds = (preds > threshold).float()\n",
    "    \n",
    "    # Flatten the tensors to compare corresponding pixels\n",
    "    preds = preds.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum()\n",
    "    \n",
    "    # Compute Dice score\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "def jaccard_index(preds, targets, threshold=0.5, epsilon=1e-6):\n",
    "    # Apply threshold to get binary predictions\n",
    "    preds = (preds > threshold).float()\n",
    "    \n",
    "    # Flatten the tensors to compare corresponding pixels\n",
    "    preds = preds.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = (preds + targets).sum() - intersection\n",
    "    \n",
    "    # Compute Jaccard Index\n",
    "    jaccard = (intersection + epsilon) / (union + epsilon)\n",
    "    \n",
    "    return jaccard\n",
    "\n",
    "def balanced_average_hausdorff_distance(predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the balanced average Hausdorff distance between predictions and targets.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (torch.Tensor):\n",
    "            The predicted tensor.\n",
    "        targets (torch.Tensor):\n",
    "            The target tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor:\n",
    "            The balanced average Hausdorff distance.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, channels, *_ = targets.shape\n",
    "    values = torch.zeros((batch_size, channels))\n",
    "\n",
    "    for batch in range(batch_size):\n",
    "        for channel in range(channels):\n",
    "            targets_, predictions_ = (\n",
    "                targets[batch][channel].detach().cpu(),\n",
    "                predictions[batch][channel].detach().cpu(),\n",
    "            )\n",
    "            values[batch, channel] = (\n",
    "                directed_hausdorff(targets_, predictions_)[0]\n",
    "                + directed_hausdorff(predictions_, targets_)[0]\n",
    "                * predictions_.view(1, -1).size(1)\n",
    "                / targets_.view(1, -1).size(1)\n",
    "            ) / 2\n",
    "\n",
    "    return values.mean()\n",
    "\n",
    "def handle_empty_array(array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle empty arrays by filling them with a default value if they contain only zeros.\n",
    "\n",
    "    Args:\n",
    "        array (np.ndarray):\n",
    "            Input array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray:\n",
    "            Array with zeros replaced by a default value if the array was empty.\n",
    "    \"\"\"\n",
    "\n",
    "    if np.count_nonzero(array) == 0:\n",
    "        array[0, 0] = 1\n",
    "\n",
    "    return array\n",
    "\n",
    "def average_surface_distance(\n",
    "    predictions: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5, connectivity: int = 1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the average surface distance between two binary segmentation masks.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (torch.Tensor):\n",
    "            The first binary segmentation mask tensor.\n",
    "        targets (torch.Tensor):\n",
    "            The second binary segmentation mask tensor.\n",
    "        threshold (float, optional):\n",
    "            Threshold value to convert predictions to binary. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor:\n",
    "            The average surface distance.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions_, targets_ = (predictions > threshold).detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
    "\n",
    "    predictions_, targets_ = handle_empty_array(predictions_), handle_empty_array(targets_)\n",
    "\n",
    "    return asd(predictions_, targets_)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    dice_scores = []\n",
    "    jaccard_scores = []\n",
    "    hausdorff_distances = []\n",
    "    surface_distances = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass to get model predictions\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Apply sigmoid or softmax if needed (for binary/multi-class segmentation)\n",
    "            outputs = torch.sigmoid(outputs) if outputs.shape[1] == 1 else torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Calculate dice score per batch\n",
    "            # Calculate dice score and jaccard index per batch\n",
    "            dice = dice_coefficient(outputs, targets)\n",
    "            jaccard = jaccard_index(outputs, targets)\n",
    "            hausdorff = balanced_average_hausdorff_distance(outputs, targets)\n",
    "            surface = average_surface_distance(outputs, targets)\n",
    "            \n",
    "            dice_scores.append(dice.item())\n",
    "            jaccard_scores.append(jaccard.item())\n",
    "            hausdorff_distances.append(hausdorff)\n",
    "            surface_distances.append(surface)\n",
    "    \n",
    "    # Calculate the mean Dice and Jaccard coefficients\n",
    "    mean_dice = sum(dice_scores) / len(dice_scores)\n",
    "    mean_jaccard = sum(jaccard_scores) / len(jaccard_scores)\n",
    "    mean_hausdorff = sum(hausdorff_distances) / len(hausdorff_distances)\n",
    "    mean_surface = sum(surface_distances) / len(surface_distances)\n",
    "\n",
    "    print(f\"Mean Dice Coefficient: {mean_dice:.4f}\")\n",
    "    print(f\"Mean Jaccard Index: {mean_jaccard:.4f}\")\n",
    "    print(f\"Mean Balanced Average Hausdorff Distance: {mean_hausdorff:.4f}\")\n",
    "    print(f\"Mean Average Surface Distance: {mean_surface:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: DenseNet201 - Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.6877\n",
      "Epoch 1/24, Loss: 0.4273\n",
      "Epoch 2/24, Loss: 0.3333\n",
      "Epoch 3/24, Loss: 0.2834\n",
      "Epoch 4/24, Loss: 0.2490\n",
      "Epoch 5/24, Loss: 0.2236\n",
      "Epoch 6/24, Loss: 0.2030\n",
      "Epoch 7/24, Loss: 0.1873\n",
      "Epoch 8/24, Loss: 0.1679\n",
      "Epoch 9/24, Loss: 0.1466\n",
      "Epoch 10/24, Loss: 0.1295\n",
      "Epoch 11/24, Loss: 0.1197\n",
      "Epoch 12/24, Loss: 0.1066\n",
      "Epoch 13/24, Loss: 0.0988\n",
      "Epoch 14/24, Loss: 0.0892\n",
      "Epoch 15/24, Loss: 0.0812\n",
      "Epoch 16/24, Loss: 0.0733\n",
      "Epoch 17/24, Loss: 0.0679\n",
      "Epoch 18/24, Loss: 0.0631\n",
      "Epoch 19/24, Loss: 0.0593\n",
      "Epoch 20/24, Loss: 0.0542\n",
      "Epoch 21/24, Loss: 0.0510\n",
      "Epoch 22/24, Loss: 0.0485\n",
      "Epoch 23/24, Loss: 0.0454\n",
      "Epoch 24/24, Loss: 0.0427\n",
      "Mean Dice Coefficient: 0.7967\n",
      "Mean Jaccard Index: 0.6739\n",
      "Mean Balanced Average Hausdorff Distance: 3.4062\n",
      "Mean Average Surface Distance: 0.4905\n",
      "Modelo treinado e salvo no disco.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Função de pré-processamento\n",
    "preprocess_input = get_preprocessing_fn('densenet201', pretrained='imagenet')\n",
    "\n",
    "# Definindo o modelo\n",
    "densenet201_unet_model = Unet(encoder_name=\"densenet201\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(densenet201_unet_model.parameters(), lr=1e-4)\n",
    "\n",
    "model_path = 'densenet201_unet_model.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    densenet201_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado a partir do disco.\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    train_model(densenet201_unet_model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
    "    evaluate_model(densenet201_unet_model, val_dataloader, device)\n",
    "    \n",
    "    # Salvando o modelo\n",
    "    torch.save(densenet201_unet_model.state_dict(), model_path)\n",
    "    print(\"Modelo treinado e salvo no disco.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Resnet152 - Decoder: UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.5489\n",
      "Epoch 1/24, Loss: 0.3534\n",
      "Epoch 2/24, Loss: 0.2680\n",
      "Epoch 3/24, Loss: 0.2225\n",
      "Epoch 4/24, Loss: 0.1904\n",
      "Epoch 5/24, Loss: 0.1656\n",
      "Epoch 6/24, Loss: 0.1489\n",
      "Epoch 7/24, Loss: 0.1354\n",
      "Epoch 8/24, Loss: 0.1203\n",
      "Epoch 9/24, Loss: 0.1071\n",
      "Epoch 10/24, Loss: 0.0966\n",
      "Epoch 11/24, Loss: 0.0870\n",
      "Epoch 12/24, Loss: 0.0784\n",
      "Epoch 13/24, Loss: 0.0704\n",
      "Epoch 14/24, Loss: 0.0646\n",
      "Epoch 15/24, Loss: 0.0589\n",
      "Epoch 16/24, Loss: 0.0544\n",
      "Epoch 17/24, Loss: 0.0508\n",
      "Epoch 18/24, Loss: 0.0475\n",
      "Epoch 19/24, Loss: 0.0441\n",
      "Epoch 20/24, Loss: 0.0411\n",
      "Epoch 21/24, Loss: 0.0376\n",
      "Epoch 22/24, Loss: 0.0358\n",
      "Epoch 23/24, Loss: 0.0333\n",
      "Epoch 24/24, Loss: 0.0329\n",
      "Mean Dice Coefficient: 0.7017\n",
      "Mean Jaccard Index: 0.5767\n",
      "Mean Balanced Average Hausdorff Distance: 3.4220\n",
      "Mean Average Surface Distance: 1.7786\n",
      "Modelo treinado e salvo no disco.\n"
     ]
    }
   ],
   "source": [
    "# Função de pré-processamento\n",
    "preprocess_input = get_preprocessing_fn('resnet152', pretrained='imagenet')\n",
    "\n",
    "# Definindo o modelo\n",
    "resnet152_unet_model = Unet(encoder_name=\"resnet152\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet152_unet_model.parameters(), lr=1e-4)\n",
    "\n",
    "model_path = 'resnet152_unet_model.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    resnet152_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado a partir do disco.\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    train_model(resnet152_unet_model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
    "    evaluate_model(resnet152_unet_model, val_dataloader, device)\n",
    "    \n",
    "    # Salvando o modelo\n",
    "    torch.save(resnet152_unet_model.state_dict(), model_path)\n",
    "    print(\"Modelo treinado e salvo no disco.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: VGG19 - Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\Vitor/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:50<00:00, 11.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.6300\n",
      "Epoch 1/24, Loss: 0.4263\n",
      "Epoch 2/24, Loss: 0.3444\n",
      "Epoch 3/24, Loss: 0.2990\n",
      "Epoch 4/24, Loss: 0.2667\n",
      "Epoch 5/24, Loss: 0.2337\n",
      "Epoch 6/24, Loss: 0.2125\n",
      "Epoch 7/24, Loss: 0.1957\n",
      "Epoch 8/24, Loss: 0.1696\n",
      "Epoch 9/24, Loss: 0.1472\n",
      "Epoch 10/24, Loss: 0.1337\n",
      "Epoch 11/24, Loss: 0.1243\n",
      "Epoch 12/24, Loss: 0.1137\n",
      "Epoch 13/24, Loss: 0.1043\n",
      "Epoch 14/24, Loss: 0.0944\n",
      "Epoch 15/24, Loss: 0.0901\n",
      "Epoch 16/24, Loss: 0.0887\n",
      "Epoch 17/24, Loss: 0.0786\n",
      "Epoch 18/24, Loss: 0.0674\n",
      "Epoch 19/24, Loss: 0.0623\n",
      "Epoch 20/24, Loss: 0.0585\n",
      "Epoch 21/24, Loss: 0.0590\n",
      "Epoch 22/24, Loss: 0.0570\n",
      "Epoch 23/24, Loss: 0.0495\n",
      "Epoch 24/24, Loss: 0.0461\n",
      "Mean Dice Coefficient: 0.8016\n",
      "Mean Jaccard Index: 0.6793\n",
      "Mean Balanced Average Hausdorff Distance: 3.2914\n",
      "Mean Average Surface Distance: 0.6692\n",
      "Modelo treinado e salvo no disco.\n"
     ]
    }
   ],
   "source": [
    "# Função de pré-processamento\n",
    "preprocess_input = get_preprocessing_fn('vgg19', pretrained='imagenet')\n",
    "\n",
    "# Definindo o modelo\n",
    "vgg19_unet_model = Unet(encoder_name=\"vgg19\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(vgg19_unet_model.parameters(), lr=1e-4)\n",
    "\n",
    "model_path = 'vgg19_unet_model.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    vgg19_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado a partir do disco.\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    train_model(vgg19_unet_model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
    "    evaluate_model(vgg19_unet_model, val_dataloader, device)\n",
    "    \n",
    "    # Salvando o modelo\n",
    "    torch.save(vgg19_unet_model.state_dict(), model_path)\n",
    "    print(\"Modelo treinado e salvo no disco.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Xception - Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth\" to C:\\Users\\Vitor/.cache\\torch\\hub\\checkpoints\\xception-43020ad28.pth\n",
      "100%|██████████| 87.4M/87.4M [04:17<00:00, 355kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.4246\n",
      "Epoch 1/24, Loss: 0.2820\n",
      "Epoch 2/24, Loss: 0.2160\n",
      "Epoch 3/24, Loss: 0.1736\n",
      "Epoch 4/24, Loss: 0.1453\n",
      "Epoch 5/24, Loss: 0.1196\n",
      "Epoch 6/24, Loss: 0.1046\n",
      "Epoch 7/24, Loss: 0.0924\n",
      "Epoch 8/24, Loss: 0.0815\n",
      "Epoch 9/24, Loss: 0.0730\n",
      "Epoch 10/24, Loss: 0.0633\n",
      "Epoch 11/24, Loss: 0.0582\n",
      "Epoch 12/24, Loss: 0.0541\n",
      "Epoch 13/24, Loss: 0.0496\n",
      "Epoch 14/24, Loss: 0.0446\n",
      "Epoch 15/24, Loss: 0.0427\n",
      "Epoch 16/24, Loss: 0.0406\n",
      "Epoch 17/24, Loss: 0.0376\n",
      "Epoch 18/24, Loss: 0.0341\n",
      "Epoch 19/24, Loss: 0.0317\n",
      "Epoch 20/24, Loss: 0.0299\n",
      "Epoch 21/24, Loss: 0.0278\n",
      "Epoch 22/24, Loss: 0.0263\n",
      "Epoch 23/24, Loss: 0.0253\n",
      "Epoch 24/24, Loss: 0.0242\n",
      "Mean Dice Coefficient: 0.7038\n",
      "Mean Jaccard Index: 0.5809\n",
      "Mean Balanced Average Hausdorff Distance: 3.3270\n",
      "Mean Average Surface Distance: 1.1955\n",
      "Modelo treinado e salvo no disco.\n"
     ]
    }
   ],
   "source": [
    "# Função de pré-processamento\n",
    "preprocess_input = get_preprocessing_fn('xception', pretrained='imagenet')\n",
    "\n",
    "# Definindo o modelo\n",
    "xception_unet_model = Unet(encoder_name=\"xception\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(xception_unet_model.parameters(), lr=1e-4)\n",
    "\n",
    "model_path = 'xception_unet_model.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    xception_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado a partir do disco.\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    train_model(xception_unet_model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
    "    evaluate_model(xception_unet_model, val_dataloader, device)\n",
    "    \n",
    "    # Salvando o modelo\n",
    "    torch.save(xception_unet_model.state_dict(), model_path)\n",
    "    print(\"Modelo treinado e salvo no disco.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: InceptionResNetV2 - Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth\" to C:\\Users\\Vitor/.cache\\torch\\hub\\checkpoints\\inceptionresnetv2-520b38e4.pth\n",
      "100%|██████████| 213M/213M [10:29<00:00, 356kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.6031\n",
      "Epoch 1/24, Loss: 0.4400\n",
      "Epoch 2/24, Loss: 0.3451\n",
      "Epoch 3/24, Loss: 0.2777\n",
      "Epoch 4/24, Loss: 0.2344\n",
      "Epoch 5/24, Loss: 0.2037\n",
      "Epoch 6/24, Loss: 0.1760\n",
      "Epoch 7/24, Loss: 0.1534\n",
      "Epoch 8/24, Loss: 0.1347\n",
      "Epoch 9/24, Loss: 0.1190\n",
      "Epoch 10/24, Loss: 0.1056\n",
      "Epoch 11/24, Loss: 0.0950\n",
      "Epoch 12/24, Loss: 0.0868\n",
      "Epoch 13/24, Loss: 0.0780\n",
      "Epoch 14/24, Loss: 0.0703\n",
      "Epoch 15/24, Loss: 0.0633\n",
      "Epoch 16/24, Loss: 0.0571\n",
      "Epoch 17/24, Loss: 0.0523\n",
      "Epoch 18/24, Loss: 0.0484\n",
      "Epoch 19/24, Loss: 0.0452\n",
      "Epoch 20/24, Loss: 0.0428\n",
      "Epoch 21/24, Loss: 0.0407\n",
      "Epoch 22/24, Loss: 0.0372\n",
      "Epoch 23/24, Loss: 0.0343\n",
      "Epoch 24/24, Loss: 0.0329\n",
      "Mean Dice Coefficient: 0.7112\n",
      "Mean Jaccard Index: 0.5908\n",
      "Mean Balanced Average Hausdorff Distance: 3.2447\n",
      "Mean Average Surface Distance: 1.2906\n",
      "Modelo treinado e salvo no disco.\n"
     ]
    }
   ],
   "source": [
    "# Função de pré-processamento\n",
    "preprocess_input = get_preprocessing_fn('inceptionresnetv2', pretrained='imagenet')\n",
    "\n",
    "# Definindo o modelo\n",
    "inceptionresnetv2_unet_model = Unet(encoder_name=\"inceptionresnetv2\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(inceptionresnetv2_unet_model.parameters(), lr=1e-4)\n",
    "\n",
    "model_path = 'inceptionresnetv2_unet_model.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    inceptionresnetv2_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado a partir do disco.\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    train_model(inceptionresnetv2_unet_model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
    "    evaluate_model(inceptionresnetv2_unet_model, val_dataloader, device)\n",
    "    \n",
    "    # Salvando o modelo\n",
    "    torch.save(inceptionresnetv2_unet_model.state_dict(), model_path)\n",
    "    print(\"Modelo treinado e salvo no disco.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: MobileNetV2 - Decoder: UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\Vitor/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:01<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 0.6342\n",
      "Epoch 1/24, Loss: 0.4535\n",
      "Epoch 2/24, Loss: 0.3679\n",
      "Epoch 3/24, Loss: 0.3081\n",
      "Epoch 4/24, Loss: 0.2635\n",
      "Epoch 5/24, Loss: 0.2270\n",
      "Epoch 6/24, Loss: 0.2051\n",
      "Epoch 7/24, Loss: 0.1785\n",
      "Epoch 8/24, Loss: 0.1591\n",
      "Epoch 9/24, Loss: 0.1389\n",
      "Epoch 10/24, Loss: 0.1272\n",
      "Epoch 11/24, Loss: 0.1138\n",
      "Epoch 12/24, Loss: 0.1028\n",
      "Epoch 13/24, Loss: 0.0922\n",
      "Epoch 14/24, Loss: 0.0841\n",
      "Epoch 15/24, Loss: 0.0781\n",
      "Epoch 16/24, Loss: 0.0724\n",
      "Epoch 17/24, Loss: 0.0671\n",
      "Epoch 18/24, Loss: 0.0624\n",
      "Epoch 19/24, Loss: 0.0597\n",
      "Epoch 20/24, Loss: 0.0567\n",
      "Epoch 21/24, Loss: 0.0516\n",
      "Epoch 22/24, Loss: 0.0473\n",
      "Epoch 23/24, Loss: 0.0445\n",
      "Epoch 24/24, Loss: 0.0423\n",
      "Mean Dice Coefficient: 0.6831\n",
      "Mean Jaccard Index: 0.5531\n",
      "Mean Balanced Average Hausdorff Distance: 3.5195\n",
      "Mean Average Surface Distance: 1.7420\n",
      "Modelo treinado e salvo no disco.\n"
     ]
    }
   ],
   "source": [
    "# Função de pré-processamento\n",
    "preprocess_input = get_preprocessing_fn('mobilenet_v2', pretrained='imagenet')\n",
    "\n",
    "# Definindo o modelo\n",
    "mobilenetv2_unet_model = Unet(encoder_name=\"mobilenet_v2\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(mobilenetv2_unet_model.parameters(), lr=1e-4)\n",
    "\n",
    "model_path = 'mobilenetv2_unet_model.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    mobilenetv2_unet_model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Modelo carregado a partir do disco.\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    train_model(mobilenetv2_unet_model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
    "    evaluate_model(mobilenetv2_unet_model, val_dataloader, device)\n",
    "    \n",
    "    # Salvando o modelo\n",
    "    torch.save(mobilenetv2_unet_model.state_dict(), model_path)\n",
    "    print(\"Modelo treinado e salvo no disco.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
