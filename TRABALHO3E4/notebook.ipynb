{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time  # Para medir o tempo\n",
    "import itertools  # Para plotar a matriz de confusão\n",
    "from tensorflow.keras.applications import (\n",
    "    DenseNet201,\n",
    "    ResNet152V2,\n",
    "    NASNetLarge,\n",
    "    VGG19,\n",
    "    Xception,\n",
    "    InceptionV3,\n",
    "    InceptionResNetV2,\n",
    "    MobileNetV2\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório dos dados\n",
    "DATA_DIR = '../DATA/classification'\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)  # Será ajustado conforme o modelo\n",
    "EPOCHS = 30\n",
    "\n",
    "NUM_CLASSES = 3  # benign, malignant, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 665 images belonging to 3 classes.\n",
      "Found 115 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.15  # 15% dos dados para validação\n",
    ")\n",
    "\n",
    "\n",
    "# Gerador para o conjunto de treinamento\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    classes=['benign', 'malignant', 'normal'],\n",
    ")\n",
    "\n",
    "# Gerador para o conjunto de validação\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    classes=['benign', 'malignant', 'normal'],\n",
    ")\n",
    "\n",
    "# Obter os nomes das classes a partir do gerador\n",
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model, num_classes):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Camada de pooling global\n",
    "    x = Dense(1024, activation='relu')(x)  # Camada totalmente conectada\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)  # Camada de saída\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models_to_evaluate = [\n",
    "    ('DenseNet201', DenseNet201),\n",
    "    ('ResNet152V2', ResNet152V2),\n",
    "    ('NASNetLarge', NASNetLarge),\n",
    "    ('VGG19', VGG19),\n",
    "    ('Xception', Xception),\n",
    "    ('InceptionV3', InceptionV3),\n",
    "    ('InceptionResNetV2', InceptionResNetV2),\n",
    "    ('MobileNetV2', MobileNetV2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando o modelo: DenseNet201\n",
      "Found 665 images belonging to 3 classes.\n",
      "Found 115 images belonging to 3 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/faculdade/TI0160-VisaoComputacionalAplicadaASaude-UFC-2024.1/.env/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - accuracy: 0.4458 - loss: 1.8944 - val_accuracy: 0.5739 - val_loss: 0.8333\n",
      "Epoch 2/30\n",
      "\u001b[1m11/21\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 4s/step - accuracy: 0.6917 - loss: 0.7102"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model_function in models_to_evaluate:\n",
    "    print(f\"\\nTreinando o modelo: {model_name}\")\n",
    "    \n",
    "    # Ajustar o tamanho da imagem conforme o requisito do modelo\n",
    "    if model_name == 'NASNetLarge':\n",
    "        IMG_SIZE = (331, 331)\n",
    "    elif model_name in ['InceptionV3', 'Xception', 'InceptionResNetV2']:\n",
    "        IMG_SIZE = (299, 299)\n",
    "    else:\n",
    "        IMG_SIZE = (224, 224)\n",
    "    \n",
    "    # Atualizar os geradores com o novo tamanho de imagem\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory=DATA_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "        classes=['benign', 'malignant', 'normal'],\n",
    "    )\n",
    "\n",
    "    # Gerador para o conjunto de validação\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        directory=DATA_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False,\n",
    "        classes=['benign', 'malignant', 'normal'],\n",
    "    )\n",
    "    \n",
    "    # Obter os nomes das classes\n",
    "    class_labels = list(train_generator.class_indices.keys())\n",
    "    \n",
    "    # Carregar o modelo base pré-treinado\n",
    "    base_model = model_function(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "    \n",
    "    # Congelar as camadas do modelo base\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Criar o modelo completo\n",
    "    model = create_model(base_model, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    # Compilar o modelo\n",
    "    learning_rate = 0.001  # Ajuste conforme necessário\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Medir o tempo de treinamento\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=True\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Medir o tempo de teste e fazer previsões\n",
    "    start_time = time.time()\n",
    "    Y_pred = model.predict(validation_generator)\n",
    "    testing_time = time.time() - start_time\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    # Obter as classes verdadeiras\n",
    "    y_true = validation_generator.classes\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, output_dict=True)\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Cálculo das curvas ROC e AUC\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    for i in range(NUM_CLASSES):\n",
    "        fpr[i], tpr[i], _ = roc_curve(\n",
    "            to_categorical(y_true, num_classes=NUM_CLASSES)[:, i],\n",
    "            Y_pred[:, i]\n",
    "        )\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Salvar os resultados\n",
    "    results.append({\n",
    "        'model_name': model_name,\n",
    "        'history': history,\n",
    "        'training_time': training_time,\n",
    "        'testing_time': testing_time,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "    \n",
    "    # Exibir as métricas\n",
    "    print(f\"Tempo de Treinamento: {training_time:.2f} segundos\")\n",
    "    print(f\"Tempo de Teste: {testing_time:.2f} segundos\")\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          model_name,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Esta função imprime e plota a matriz de confusão.\n",
    "    Normalização pode ser aplicada definindo `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matriz de Confusão Normalizada\")\n",
    "    else:\n",
    "        print('Matriz de Confusão Sem Normalização')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f'{title} - {model_name}')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Classe Verdadeira')\n",
    "    plt.xlabel('Classe Predita')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(fpr, tpr, roc_auc, classes, model_name):\n",
    "    plt.figure()\n",
    "    for i in range(len(classes)):\n",
    "        plt.plot(fpr[i], tpr[i],\n",
    "                 label='Classe {0} (AUC = {1:0.2f})'\n",
    "                       ''.format(classes[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Linha diagonal\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "    plt.title(f'Curvas ROC - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"\n",
    "    Plota a história de treinamento do modelo.\n",
    "    \n",
    "    Args:\n",
    "    history: História de treinamento retornada pelo método fit do Keras.\n",
    "    model_name: Nome do modelo.\n",
    "    \"\"\"\n",
    "    # Plotar a acurácia de treinamento e validação\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Acurácia\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "    plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "    plt.title(f'Acurácia - {model_name}')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Perda\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "    plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "    plt.title(f'Perda - {model_name}')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame para coletar as métricas globais\n",
    "df_results = pd.DataFrame(columns=['Modelo', 'Acurácia Global', 'F1-Score Global', 'Tempo de Treino (s)', 'Tempo de Teste (s)'])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for result in results:\n",
    "    model_name = result['model_name']\n",
    "    report = result['classification_report']\n",
    "    \n",
    "    # Acurácia global\n",
    "    accuracy = report['accuracy']\n",
    "    # F1-Score global (calculado como a média dos F1-Scores das classes)\n",
    "    f1_score = np.mean([report[label]['f1-score'] for label in class_labels])\n",
    "    \n",
    "    # Adicionar ao DataFrame\n",
    "    results_list.append({\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia Global': accuracy,\n",
    "        'F1-Score Global': f1_score,\n",
    "        'Tempo de Treino (s)': result['training_time'],\n",
    "        'Tempo de Teste (s)': result['testing_time']\n",
    "    })\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plot_confusion_matrix(result['confusion_matrix'], classes=class_labels, model_name=model_name, normalize=True)\n",
    "    \n",
    "    # Plotar as curvas ROC\n",
    "    plot_roc_curves(result['fpr'], result['tpr'], result['roc_auc'], class_labels, model_name)\n",
    "\n",
    "    # Plotar a história de treinamento\n",
    "    plot_training_history(history, model_name)\n",
    "\n",
    "# Converter a lista de resultados em um DataFrame\n",
    "df_results = pd.DataFrame(results_list)\n",
    "\n",
    "# Exibir o DataFrame com os resultados\n",
    "print(df_results)\n",
    "df_results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    model_name = result['model_name']\n",
    "    report = result['classification_report']\n",
    "    print(f\"\\nMétricas por classe para o modelo: {model_name}\")\n",
    "    for label in class_labels:\n",
    "        print(f\"Classe: {label}\")\n",
    "        print(f\" - Precision: {report[label]['precision']:.4f}\")\n",
    "        print(f\" - Recall: {report[label]['recall']:.4f}\")\n",
    "        print(f\" - F1-score: {report[label]['f1-score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
